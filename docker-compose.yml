services:
  # Ollama - Local LLM for prompt enhancement
  # Note: On macOS, Ollama runs natively for GPU access
  # This container is for Linux/CI environments
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: mcp-ollama
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama_models:/root/.ollama
  #   restart: unless-stopped

  # MCP Router - Main entry point
  router:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: mcp-router
    ports:
      - "${ROUTER_PORT:-9090}:9090"
    environment:
      # Note: Use explicit host.docker.internal, not shell's OLLAMA_HOST which points to localhost
      - OLLAMA_HOST=host.docker.internal
      - OLLAMA_PORT=11434
      - OLLAMA_MODEL=${OLLAMA_MODEL:-deepseek-r1:latest}
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - QDRANT_URL=http://qdrant:6333
    env_file:
      - .env
    volumes:
      - ./configs:/app/configs:ro
      - ./templates:/app/templates:ro
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      - qdrant
    # Note: MCP servers (context7, desktop-commander, sequential-thinking) are STDIO-based
    # They should be spawned as subprocesses by the router, not run as containers
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9090/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # STDIO MCP Servers - These are spawned by the router as subprocesses, not containers
  # The router uses router/adapters/stdio.py to communicate with them via stdin/stdout
  # Node.js packages are installed in the router container via package.json:
  #   - @upstash/context7-mcp
  #   - @wonderwhy-er/desktop-commander
  #   - @modelcontextprotocol/server-sequential-thinking
  #   - @modelcontextprotocol/server-memory

  # Qdrant - Vector storage for semantic prompt cache
  # Note: If port 6333 is in use (e.g., SSH tunnel to remote Qdrant), uses 6335/6336
  qdrant:
    image: qdrant/qdrant:latest
    container_name: mcp-qdrant
    ports:
      - "6335:6333"  # REST API + Dashboard (mapped to 6335 to avoid conflicts)
      - "6336:6334"  # gRPC
    volumes:
      - qdrant_storage:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
    restart: unless-stopped

volumes:
  ollama_models:
  qdrant_storage:
